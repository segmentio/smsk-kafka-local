#
# Copyright 2017 LinkedIn Corp. Licensed under the BSD 2-Clause License (the "License"). See License in the project root for license information.
#

# This is an example property file for Kafka Cruise Control. See com.linkedin.kafka.cruisecontrol.config.constants for more details.

# Configuration for the metadata client.
# =======================================

# The Kafka cluster to control.
bootstrap.servers=kafka-1:9092,kafka-2:9092,kafka-3:9092,kafka-4:9092

# The maximum interval in milliseconds between two metadata refreshes.
#metadata.max.age.ms=300000

# Client id for the Cruise Control. It is used for the metadata client.
#client.id=kafka-cruise-control

# The size of TCP send buffer bytes for the metadata client.
#send.buffer.bytes=131072

# The size of TCP receive buffer size for the metadata client.
#receive.buffer.bytes=131072

# The time to wait before disconnect an idle TCP connection.
#connections.max.idle.ms=540000

# The time to wait before reconnect to a given host.
#reconnect.backoff.ms=50

# The time to wait for a response from a host after sending a request.
#request.timeout.ms=30000

# The time to wait for broker logdir to respond after sending a request.
#logdir.response.timeout.ms=10000

# Configurations for the load monitor
# =======================================

# The number of metric fetcher thread to fetch metrics for the Kafka cluster
num.metric.fetchers=1

# The metric sampler class
metric.sampler.class=com.linkedin.kafka.cruisecontrol.monitor.sampling.CruiseControlMetricsReporterSampler

# True if the sampling process allows CPU capacity estimation of brokers used for CPU utilization estimation.
sampling.allow.cpu.capacity.estimation=true

# Configurations for CruiseControlMetricsReporterSampler
metric.reporter.topic=__CruiseControlMetrics

# The sample store class name
sample.store.class=com.linkedin.kafka.cruisecontrol.monitor.sampling.KafkaSampleStore

# The config for the Kafka sample store to save the partition metric samples
partition.metric.sample.store.topic=__KafkaCruiseControlPartitionMetricSamples

# The config for the Kafka sample store to save the model training samples
broker.metric.sample.store.topic=__KafkaCruiseControlModelTrainingSamples

# The replication factor of Kafka metric sample store topic
sample.store.topic.replication.factor=2

# The config for the number of Kafka sample store consumer threads
num.sample.loading.threads=8

# The partition assignor class for the metric samplers
metric.sampler.partition.assignor.class=com.linkedin.kafka.cruisecontrol.monitor.sampling.DefaultMetricSamplerPartitionAssignor

# The metric sampling interval in milliseconds
metric.sampling.interval.ms=120000

# The partition metrics window size in milliseconds
partition.metrics.window.ms=150000

# The number of partition metric windows to keep in memory. Partition-load-history = num.partition.metrics.windows * partition.metrics.window.ms
num.partition.metrics.windows=5

# The minimum partition metric samples required for a partition in each window
min.samples.per.partition.metrics.window=1

# The broker metrics window size in milliseconds
broker.metrics.window.ms=150000

# The number of broker metric windows to keep in memory. Broker-load-history = num.broker.metrics.windows * broker.metrics.window.ms
num.broker.metrics.windows=20

# The minimum broker metric samples required for a partition in each window
min.samples.per.broker.metrics.window=1

# The configuration for the BrokerCapacityConfigFileResolver (supports JBOD, non-JBOD, and heterogeneous CPU core capacities)
#capacity.config.file=config/capacity.json
capacity.config.file=/usr/local/cruise-control/config/capacityCores.json

# Configurations for the analyzer
# =======================================
#START####################
# LIST OF GOALS
# RackAwareGoal - Ensures that all replicas of each partition are assigned in a rack aware manner -- i.e. no more than one replica of each partition resides in the same rack.
# RackAwareDistributionGoal - A relaxed version of RackAwareGoal. Contrary to RackAwareGoal, as long as replicas of each partition can achieve a perfectly even distribution across the racks, this goal lets placement of multiple replicas of a partition into a single rack.
# MinTopicLeadersPerBrokerGoal - Ensures that each alive broker has at least a certain number of leader replica of each topic in a configured set of topics
# ReplicaCapacityGoal - Ensures that the maximum number of replicas per broker is under the specified maximum limit.
# DiskCapacityGoal - Ensures that Disk space usage of each broker is below a given threshold.
# NetworkInboundCapacityGoal - Ensures that inbound network utilization of each broker is below a given threshold.
# NetworkOutboundCapacityGoal - Ensures that outbound network utilization of each broker is below a given threshold.
# CpuCapacityGoal - Ensures that CPU utilization of each broker is below a given threshold.
# ReplicaDistributionGoal - Attempts to make all the brokers in a cluster have a similar number of replicas.
# PotentialNwOutGoal - Ensures that the potential network output (when all the replicas in the broker become leaders) on each of the broker do not exceed the brokerâ€™s network outbound bandwidth capacity.
# DiskUsageDistributionGoal - Attempts to keep the Disk space usage variance among brokers within a certain range relative to the average Disk utilization.
# NetworkInboundUsageDistributionGoal - Attempts to keep the inbound network utilization variance among brokers within a certain range relative to the average inbound network utilization.
# NetworkOutboundUsageDistributionGoal - Attempts to keep the outbound network utilization variance among brokers within a certain range relative to the average outbound network utilization.
# CpuUsageDistributionGoal - Attempts to keep the CPU usage variance among brokers within a certain range relative to the average CPU utilization.
# LeaderReplicaDistributionGoal - Attempts to make all the brokers in a cluster have a similar number of leader replicas.
# LeaderBytesInDistributionGoal - Attempts to equalize the leader bytes in rate on each host.
# TopicReplicaDistributionGoal - Attempts to maintain an even distribution of any topic's partitions across the entire cluster.
# PreferredLeaderElectionGoal - Simply move the leaders to the first replica of each partition.
# KafkaAssignerDiskUsageDistributionGoal - (Kafka-assigner mode) Attempts to distribute disk usage evenly among brokers based on swap.
# IntraBrokerDiskCapacityGoal - (Rebalance-disk mode, not available in kafka_0_11_and_1_0 branch) Ensures that Disk space usage of each disk is below a given threshold.
# IntraBrokerDiskUsageDistributionGoal - (Rebalance-disk mode, not available in kafka_0_11_and_1_0 branch) Attempts to keep the Disk space usage variance among disks within a certain range relative to the average broker Disk utilization.
# fixing only on rack aware goal

# The list of goals to optimize the Kafka cluster for with pre-computed proposals -- consider using RackAwareDistributionGoal instead of RackAwareGoal in clusters with partitions whose replication factor > number of racks
default.goals=com.linkedin.kafka.cruisecontrol.analyzer.goals.RackAwareGoal,com.linkedin.kafka.cruisecontrol.analyzer.goals.ReplicaDistributionGoal,com.linkedin.kafka.cruisecontrol.analyzer.goals.RackAwareDistributionGoal

# The list of supported goals
goals=com.linkedin.kafka.cruisecontrol.analyzer.goals.RackAwareGoal,com.linkedin.kafka.cruisecontrol.analyzer.goals.ReplicaDistributionGoal,com.linkedin.kafka.cruisecontrol.analyzer.goals.RackAwareDistributionGoal

# The list of supported intra-broker goals
intra.broker.goals=com.linkedin.kafka.cruisecontrol.analyzer.goals.IntraBrokerDiskCapacityGoal,com.linkedin.kafka.cruisecontrol.analyzer.goals.IntraBrokerDiskUsageDistributionGoal

# The list of supported hard goals -- consider using RackAwareDistributionGoal instead of RackAwareGoal in clusters with partitions whose replication factor > number of racks
hard.goals=com.linkedin.kafka.cruisecontrol.analyzer.goals.RackAwareGoal,com.linkedin.kafka.cruisecontrol.analyzer.goals.ReplicaDistributionGoal,com.linkedin.kafka.cruisecontrol.analyzer.goals.RackAwareDistributionGoal

# The minimum percentage of well monitored partitions out of all the partitions
min.valid.partition.ratio=0.95

# The balance threshold for CPU
cpu.balance.threshold=1.1

# The balance threshold for disk
disk.balance.threshold=1.1

# The balance threshold for network inbound utilization
network.inbound.balance.threshold=1.1

# The balance threshold for network outbound utilization
network.outbound.balance.threshold=1.1

# The balance threshold for the replica count
replica.count.balance.threshold=1.1

# The capacity threshold for CPU in percentage
cpu.capacity.threshold=0.7

# The capacity threshold for disk in percentage
disk.capacity.threshold=0.8

# The capacity threshold for network inbound utilization in percentage
network.inbound.capacity.threshold=0.8

# The capacity threshold for network outbound utilization in percentage
network.outbound.capacity.threshold=0.8

# The threshold to define the cluster to be in a low CPU utilization state
cpu.low.utilization.threshold=0.0

# The threshold to define the cluster to be in a low disk utilization state
disk.low.utilization.threshold=0.0

# The threshold to define the cluster to be in a low network inbound utilization state
network.inbound.low.utilization.threshold=0.0

# The threshold to define the cluster to be in a low network outbound utilization state
network.outbound.low.utilization.threshold=0.0

# The metric anomaly percentile upper threshold
metric.anomaly.percentile.upper.threshold=90.0

# The metric anomaly percentile lower threshold
metric.anomaly.percentile.lower.threshold=10.0

# How often should the cached proposal be expired and recalculated if necessary
proposal.expiration.ms=60000

# The maximum number of replicas that can reside on a broker at any given time.
max.replicas.per.broker=10000

# The number of threads to use for proposal candidate precomputing.
num.proposal.precompute.threads=1

# the topics that should be excluded from the partition movement.
#topics.excluded.from.partition.movement

# The impact of having one level higher goal priority on the relative balancedness score.
#goal.balancedness.priority.weight

# The impact of strictness on the relative balancedness score.
#goal.balancedness.strictness.weight

# Configurations for the executor
# =======================================

# The zookeeper connect of the Kafka cluster
zookeeper.connect=zookeeper:2181/

# If true, appropriate zookeeper Client { .. } entry required in jaas file located at $base_dir/config/cruise_control_jaas.conf
zookeeper.security.enabled=false

# The max number of partitions to move in/out on a given broker at a given time.
num.concurrent.partition.movements.per.broker=10

# The max number of partitions to move between disks within a given broker at a given time.
num.concurrent.intra.broker.partition.movements=2

# The max number of leadership movement within the whole cluster at a given time.
num.concurrent.leader.movements=1000

# Default replica movement throttle. If not specified, movements unthrottled by default.
# default.replication.throttle=

# The interval between two execution progress checks.
execution.progress.check.interval.ms=10000


# Configurations for anomaly detector
# =======================================

# The goal violation notifier class
anomaly.notifier.class=com.linkedin.kafka.cruisecontrol.detector.notifier.SelfHealingNotifier

# The metric anomaly finder class
metric.anomaly.finder.class=com.linkedin.kafka.cruisecontrol.detector.KafkaMetricAnomalyFinder

# The anomaly detection interval
anomaly.detection.interval.ms=120000

# The goal violation to detect -- consider using RackAwareDistributionGoal instead of RackAwareGoal in clusters with partitions whose replication factor > number of racks
# anomaly.detection.goals=com.linkedin.kafka.cruisecontrol.analyzer.goals.RackAwareGoal,com.linkedin.kafka.cruisecontrol.analyzer.goals.ReplicaCapacityGoal,com.linkedin.kafka.cruisecontrol.analyzer.goals.DiskCapacityGoal,com.linkedin.kafka.cruisecontrol.analyzer.goals.NetworkInboundCapacityGoal,com.linkedin.kafka.cruisecontrol.analyzer.goals.NetworkOutboundCapacityGoal,com.linkedin.kafka.cruisecontrol.analyzer.goals.CpuCapacityGoal
anomaly.detection.goals=com.linkedin.kafka.cruisecontrol.analyzer.goals.RackAwareGoal,com.linkedin.kafka.cruisecontrol.analyzer.goals.ReplicaDistributionGoal,com.linkedin.kafka.cruisecontrol.analyzer.goals.RackAwareDistributionGoal

# The interested metrics for metric anomaly analyzer.
metric.anomaly.analyzer.metrics=BROKER_PRODUCE_LOCAL_TIME_MS_50TH,BROKER_PRODUCE_LOCAL_TIME_MS_999TH,BROKER_CONSUMER_FETCH_LOCAL_TIME_MS_50TH,BROKER_CONSUMER_FETCH_LOCAL_TIME_MS_999TH,BROKER_FOLLOWER_FETCH_LOCAL_TIME_MS_50TH,BROKER_FOLLOWER_FETCH_LOCAL_TIME_MS_999TH,BROKER_LOG_FLUSH_TIME_MS_50TH,BROKER_LOG_FLUSH_TIME_MS_999TH

# True if recently demoted brokers are excluded from optimizations during self healing, false otherwise
self.healing.exclude.recently.demoted.brokers=true

# True if recently removed brokers are excluded from optimizations during self healing, false otherwise
self.healing.exclude.recently.removed.brokers=false

# The zk path to store failed broker information.
failed.brokers.zk.path=/CruiseControlBrokerList

# Topic config provider class
topic.config.provider.class=com.linkedin.kafka.cruisecontrol.config.KafkaTopicConfigProvider

# The cluster configurations for the KafkaTopicConfigProvider
cluster.configs.file=/usr/local/cruise-control/config/clusterConfigs.json

# The maximum time in milliseconds to store the response and access details of a completed kafka monitoring user task.
completed.kafka.monitor.user.task.retention.time.ms=86400000

# The maximum time in milliseconds to store the response and access details of a completed cruise control monitoring user task.
completed.cruise.control.monitor.user.task.retention.time.ms=86400000

# The maximum time in milliseconds to store the response and access details of a completed kafka admin user task.
completed.kafka.admin.user.task.retention.time.ms=604800000

# The maximum time in milliseconds to store the response and access details of a completed cruise control admin user task.
completed.cruise.control.admin.user.task.retention.time.ms=604800000

# The fallback maximum time in milliseconds to store the response and access details of a completed user task.
completed.user.task.retention.time.ms=86400000

# The maximum time in milliseconds to retain the demotion history of brokers.
demotion.history.retention.time.ms=1209600000

# The maximum time in milliseconds to retain the removal history of brokers.
removal.history.retention.time.ms=1209600000

# The maximum number of completed kafka monitoring user tasks for which the response and access details will be cached.
max.cached.completed.kafka.monitor.user.tasks=20

# The maximum number of completed cruise control monitoring user tasks for which the response and access details will be cached.
max.cached.completed.cruise.control.monitor.user.tasks=20

# The maximum number of completed kafka admin user tasks for which the response and access details will be cached.
max.cached.completed.kafka.admin.user.tasks=30

# The maximum number of completed cruise control admin user tasks for which the response and access details will be cached.
max.cached.completed.cruise.control.admin.user.tasks=30

# The fallback maximum number of completed user tasks of certain type for which the response and access details will be cached.
max.cached.completed.user.tasks=25

# The maximum number of user tasks for concurrently running in async endpoints across all users.
max.active.user.tasks=5

# Enable self healing for all anomaly detectors, unless the particular anomaly detector is explicitly disabled
self.healing.enabled=false

# Enable self healing for broker failure detector
broker.failure.alert.threshold.ms=30000
broker.failure.self.healing.threshold.ms=30000
self.healing.broker.failure.enabled=true

# Enable self healing for goal violation detector
self.healing.goal.violation.enabled=true

# Enable self healing for metric anomaly detector
#self.healing.metric.anomaly.enabled=true

# Enable self healing for disk failure detector
#self.healing.disk.failure.enabled=true

# Enable self healing for topic anomaly detector
#self.healing.topic.anomaly.enabled=true
#topic.anomaly.finder.class=com.linkedin.kafka.cruisecontrol.detector.TopicReplicationFactorAnomalyFinder

# Enable self healing for maintenance event detector
#self.healing.maintenance.event.enabled=true

# The multiplier applied to the threshold of distribution goals used by goal.violation.detector.
#goal.violation.distribution.threshold.multiplier=2.50

# configurations for the webserver
# ================================

# HTTP listen port
webserver.http.port=9090

# HTTP listen address
webserver.http.address=0.0.0.0

# Whether CORS support is enabled for API or not
webserver.http.cors.enabled=false

# Value for Access-Control-Allow-Origin
webserver.http.cors.origin=http://localhost:9090

# Value for Access-Control-Request-Method
webserver.http.cors.allowmethods=OPTIONS,GET,POST

# Headers that should be exposed to the Browser (Webapp)
# This is a special header that is used by the
# User Tasks subsystem and should be explicitly
# Enabled when CORS mode is used as part of the
# Admin Interface
webserver.http.cors.exposeheaders=User-Task-ID,Content-Type

# REST API default prefix (dont forget the ending /*)
webserver.api.urlprefix=/kafkacruisecontrol/*

# Location where the Cruise Control frontend is deployed
webserver.ui.diskpath=./cruise-control-ui/dist/

# URL path prefix for UI (dont forget the ending /*)
webserver.ui.urlprefix=/*

# Time After which request is converted to Async
webserver.request.maxBlockTimeMs=10000

# Default Session Expiry Period
webserver.session.maxExpiryTimeMs=60000

# Session cookie path
webserver.session.path=/

# Server Access Logs
webserver.accesslog.enabled=false

# Location of HTTP Request Logs
webserver.accesslog.path=access.log

# HTTP Request Log retention days
webserver.accesslog.retention.days=14

# Configurations for servlet
# ==========================

# Enable two-step verification for processing POST requests.
two.step.verification.enabled=false

# The maximum time in milliseconds to retain the requests in two-step (verification) purgatory.
two.step.purgatory.retention.time.ms=1209600000

# The maximum number of requests in two-step (verification) purgatory.
two.step.purgatory.max.requests=25
